# app.py
# Interface utilisateur Streamlit pour l'agent d'analyse de contenu YouTube.

import streamlit as st
import pandas as pd
import os
import threading
import time
from youtube_agent import (
    run_full_analysis, 
    get_video_details, 
    get_cached_transcription,
    estimate_processing_time,
    format_time,
    get_average_processing_speed,
    TRANSCRIPTIONS_DIR
)
import json
from pathlib import Path

QUEUE_FILE = Path("jobs_queue.json")

def get_queue_status():
    if QUEUE_FILE.exists():
        try:
            queue = json.loads(QUEUE_FILE.read_text(encoding="utf-8"))
        except Exception:
            return 0, 0, 0, 0
        total = len(queue)
        done = sum(1 for job in queue if job.get("status") == "done")
        running = sum(1 for job in queue if job.get("status") == "running")
        pending = sum(1 for job in queue if job.get("status") == "pending")
        return total, done, running, pending
    return 0, 0, 0, 0

def estimate_time_left(avg_speed, queue):
    # avg_speed en secondes par vid√©o
    remaining = sum(1 for job in queue if job.get("status") in ("pending", "running"))
    return avg_speed * remaining

def enqueue_jobs(video_urls, keywords, whisper_model, reset_queue=False):
    if reset_queue or not QUEUE_FILE.exists():
        queue = []
    else:
        try:
            queue = json.loads(QUEUE_FILE.read_text(encoding="utf-8"))
        except Exception:
            queue = []
    for url in video_urls:
        job = {
            "url": url,
            "keywords": keywords,
            "model": whisper_model,
            "status": "pending",
            "created_at": time.time()
        }
        queue.append(job)
    QUEUE_FILE.write_text(json.dumps(queue, ensure_ascii=False, indent=2), encoding="utf-8")

st.set_page_config(page_title="Agent d'Analyse YouTube", layout="wide")

# Initialisation de l'√©tat de la session
if 'video_df' not in st.session_state:
    st.session_state.video_df = None
if 'analysis_running' not in st.session_state:
    st.session_state.analysis_running = False
if 'stop_analysis' not in st.session_state:
    st.session_state.stop_analysis = False
if 'fetching_videos' not in st.session_state:
    st.session_state.fetching_videos = False
if 'fetching_error' not in st.session_state:
    st.session_state.fetching_error = None

st.title("ü§ñ Agent d'Analyse de Contenu YouTube")
st.markdown("""
Cette application utilise le mod√®le **Whisper auto-h√©berg√©** pour analyser les vid√©os d'une cha√Æne YouTube.  
**√âtape 1 :** Listez les vid√©os.  
**√âtape 2 :** S√©lectionnez les vid√©os et le mod√®le, puis lancez l'analyse.
""")

# --- Panneau de configuration dans la barre lat√©rale ---
with st.sidebar:
    st.header("Configuration de l'Analyse")
    
    st.subheader("√âtape 1 : Lister les vid√©os")
    url_input = st.text_input(
        "URL de la cha√Æne ou d'une vid√©o",
        placeholder="Collez une URL ici..."
    )
    list_videos_button = st.button(
        "Lister la/les vid√©o(s)",
        disabled=st.session_state.fetching_videos
    )

    st.subheader("√âtape 2 : Choisir le mod√®le")
    whisper_model = st.selectbox(
        "Taille du mod√®le Whisper",
        ("tiny", "base", "small", "medium", "large-v2"),
        index=2,  # 'small' par d√©faut
        help="Les mod√®les plus grands sont plus pr√©cis mais beaucoup plus lents et gourmands en ressources. 'base' est un bon d√©but.",
        disabled=st.session_state.fetching_videos
    )

    st.subheader("Suivi du traitement")
    total, done, running, pending = get_queue_status()
    st.write(f"Total vid√©os en file : **{total}**")
    st.write(f"D√©j√† trait√©es : **{done}**")
    st.write(f"En cours : **{running}**")
    st.write(f"En attente : **{pending}**")

    # Estimation du temps restant (optionnel)
    if total > 0:
        try:
            queue = json.loads(QUEUE_FILE.read_text(encoding="utf-8"))
            avg_speed = get_average_processing_speed("base")  # ou le mod√®le choisi
            time_left = estimate_time_left(avg_speed, queue)
            st.write(f"Estimation du temps restant : **{format_time(time_left)}**")
        except Exception:
            pass

    st.subheader("Lancer le worker en arri√®re-plan")
    st.markdown("Copiez la commande ci-dessous pour emp√™cher la mise en veille pendant le traitement‚ÄØ:")
    st.code("caffeinate -i python3 youtube_worker.py", language="bash")
    st.button("üìã Copier la commande", on_click=lambda: st.session_state.update({"copied": True}))
    if st.session_state.get("copied"):
        st.success("Commande copi√©e dans le presse-papier‚ÄØ!")

# --- Logique pour lister les vid√©os ---
if list_videos_button and url_input and not st.session_state.fetching_videos:
    st.session_state.fetching_videos = True
    st.session_state.fetching_error = None
    st.session_state.video_df = None

if st.session_state.fetching_videos:
    with st.spinner("R√©cup√©ration des informations..."):
        try:
            videos_list = get_video_details(url_input)
            if videos_list:
                df = pd.DataFrame(videos_list)
                df.insert(0, "S√©lectionner", True)
                st.session_state.video_df = df
                st.session_state.fetching_videos = False
            else:
                st.session_state.fetching_error = "Impossible de r√©cup√©rer les informations. V√©rifiez l'URL."
                st.session_state.video_df = None
                st.session_state.fetching_videos = False
        except Exception as e:
            st.session_state.fetching_error = f"Erreur lors de la r√©cup√©ration : {e}"
            st.session_state.video_df = None
            st.session_state.fetching_videos = False

if st.session_state.fetching_error:
    st.error(st.session_state.fetching_error)

# --- Fonction pour v√©rifier si une vid√©o est en cache ---
def is_video_cached(url: str) -> bool:
    """V√©rifie si une vid√©o a d√©j√† √©t√© transcrite"""
    return get_cached_transcription(url) is not None

# --- Affichage du s√©lecteur de vid√©os et du panneau d'analyse ---
if st.session_state.video_df is not None:
    st.header("Vid√©os √† analyser")

    # Boutons pour s√©lectionner/d√©s√©lectionner toutes les vid√©os
    col_select_all, col_deselect_all = st.columns(2)
    
    select_all_clicked = False
    deselect_all_clicked = False
    
    with col_select_all:
        if st.button("‚úÖ Tout s√©lectionner", key="select_all"):
            st.session_state.video_df["S√©lectionner"] = True
            select_all_clicked = True
    
    with col_deselect_all:
        if st.button("‚ùå Tout d√©s√©lectionner", key="deselect_all"):
            st.session_state.video_df["S√©lectionner"] = False
            deselect_all_clicked = True

    # Ajouter une colonne indiquant si la vid√©o est en cache
    df_display = st.session_state.video_df.copy()
    df_display["üìÅ Cached"] = df_display["url"].apply(
        lambda url: "‚úÖ Disponible" if is_video_cached(url) else "‚è≥ √Ä t√©l√©charger"
    )

    # --- SUPPRIM√â : colonne Temps estim√© ---
    # df_display["‚è±Ô∏è Temps estim√©"] = df_display.apply(
    #     lambda row: "‚úÖ En cache" if "‚úÖ" in row["üìÅ Cached"] else "N/A",
    #     axis=1
    # )

    # Trier pour que les vid√©os √Ä t√©l√©charger apparaissent en premier
    df_display = df_display.sort_values(
        "üìÅ Cached",
        key=lambda x: x.apply(lambda v: 0 if "‚è≥" in str(v) else 1)
    ).reset_index(drop=True)

    edited_df = st.data_editor(
        df_display,
        column_config={
            "S√©lectionner": st.column_config.CheckboxColumn(
                "Votre s√©lection",
                default=True,
            ),
            "title": st.column_config.TextColumn("Titre de la vid√©o"),
            "duration": st.column_config.TextColumn("Dur√©e"),
            "url": st.column_config.LinkColumn("URL", display_text="Lien"),
            "üìÅ Cached": st.column_config.TextColumn("√âtat du cache"),
            # "‚è±Ô∏è Temps estim√©": st.column_config.TextColumn("Temps estim√©")  # supprim√©
        },
        disabled=["title", "duration", "url", "üìÅ Cached"],  # "‚è±Ô∏è Temps estim√©" retir√©
        hide_index=True,
        height=400,
        key="video_selector"
    )

    selected_videos = edited_df[edited_df["S√©lectionner"]]

    st.header("Lancer l'analyse locale")
    st.info(f"{len(selected_videos)} vid√©o(s) s√©lectionn√©e(s) avec le mod√®le **{whisper_model}**.")
    
    # Afficher les estimations de temps (avec mise en cache)
    if len(selected_videos) > 0:
        avg_speed = get_average_processing_speed(whisper_model)
        
        # Calculer le temps estim√© pour chaque vid√©o
        estimated_times = []
        total_estimated_time = 0
        
        for idx, row in selected_videos.iterrows():
            url = row['url']
            title = row['title']
            # V√©rifier d'abord si en cache
            if is_video_cached(url):
                estimated_time = 0
                estimated_times.append((title, 0))
            else:
                # Pour les vid√©os non cach√©es, on utilise une estimation simple
                # On calcule le temps estim√© quand on lance l'analyse
                estimated_times.append((title, None))
            
        if estimated_times:
            videos_to_process = sum(1 for _, t in estimated_times if t is None)
            if avg_speed and videos_to_process > 0:
                st.info(f"üìä **Vitesse moyenne** : {avg_speed:.2f}x (bas√©e sur vid√©os pr√©c√©dentes)")
            
            with st.expander(f"üìã D√©tails des {len(estimated_times)} vid√©o(s) s√©lectionn√©e(s)"):
                for title, est_time in estimated_times:
                    if est_time == 0:
                        st.write(f"‚úÖ {title[:60]} - En cache")
                    elif est_time is None:
                        st.write(f"‚è≥ {title[:60]} - √Ä traiter")
                    else:
                        st.write(f"‚è±Ô∏è {title[:60]} - {format_time(est_time)}")

    # --- SUPPRIM√â : Section mots-cl√©s ---
    # keywords_input = st.text_area(
    #     "Mots-cl√©s √† rechercher (s√©par√©s par des virgules)",
    #     placeholder="Ex: intelligence artificielle, √©thique, philosophie"
    # )

    # Cr√©er deux colonnes pour les boutons
    col1, col2 = st.columns([4, 1])
    
    with col1:
        start_analysis = st.button("üöÄ Lancer l'Analyse Locale", key="start_btn")
    
    with col2:
        stop_analysis = st.button("‚èπÔ∏è Arr√™ter", key="stop_btn")
    
    if stop_analysis:
        st.session_state.stop_analysis = True

    if start_analysis:
        if selected_videos.empty:
            st.warning("Veuillez s√©lectionner au moins une vid√©o √† analyser.")
        else:
            video_urls_to_analyze = selected_videos['url'].tolist()
            enqueue_jobs(video_urls_to_analyze, [], whisper_model, reset_queue=True)
            st.success(f"{len(video_urls_to_analyze)} vid√©o(s) ajout√©e(s) √† la file d'attente.")
            st.info("Lancez le worker en arri√®re-plan pour traiter la file :\n\n```bash\ncaffeinate -i python3 youtube_worker.py\n```")
            if st.button("üìã Copier la commande", key="copy_worker_cmd_main"):
                st.session_state["copied_main"] = True
                st.code("caffeinate -i python3 youtube_worker.py", language="bash")
            if st.session_state.get("copied_main"):
                st.success("Commande copi√©e dans le presse-papier‚ÄØ!")